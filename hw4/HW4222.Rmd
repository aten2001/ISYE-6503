---
Ttile: Homework 4
output:
  word_document: default
  html_document:
    df_print: paged
---


  ```{r}
library("GGally")
library("DAAG")
library(tree)
library(randomForest)
library(pROC)
set.seed(1234)
```



#Question 10.3
#1. Using the GermanCredit data set germancredit.txt, use logistic
#regression to find a good predictive model for whether credit applicants are good credit risks or
#not. Show your model (factors used and their coefficients), the software output, and the quality
#of fit. 
```{r}
credit<- read.table("german.data")
head(credit)
str(credit)
```

#accordingly to the description, we found that V21 is the response. 1 means good, 2 means bad.
#Recode the V21 to be a 0/1 variable, instead of 1/2
```{r}
credit$V21[credit$V21==1]<-0
credit$V21[credit$V21==2]<-1
```

# Divide the data into training and test datasets.
```{r}
trainno <- sample(1:nrow(credit), size = round(nrow(credit)*0.7), replace = FALSE)
train <- credit[trainno,]
test<- credit[-trainno,]
```

#Fit the logistic model
```{r}
log<-glm(V21~.,data=train,family=binomial(link="logit"))
summary(log)
```

#keep the significant preditors under p-value=0.1,for the categorical predictors, keep them if any of the categories are significant. Then re-fit the model
```{r}
log2<-glm(V21~V1+V2+V3+V4+V5+V6+V7+V8+V9+V10+V12+V14+V16+V19+V20,data=train,family=binomial(link="logit"))
summary(log2)
```
#For the categorical variables, not all the levels are significant. So create a binary (0/1) variable for each of them: 0 for not significant, 1 for significant
```{r}
train$V1A12[train$V1=="A12"]<-1
train$V1A12[train$V1!="A12"]<-0

train$V1A13[train$V1=="A13"]<-1
train$V1A13[train$V1!="A13"]<-0

train$V1A14[train$V1=="A14"]<-1
train$V1A14[train$V1!="A14"]<-0

train$V3A34[train$V1=="A34"]<-1
train$V3A34[train$V1!="A34"]<-0

train$V4A41[train$V1=="A41"]<-1
train$V4A41[train$V1!="A41"]<-0

train$V4A42[train$V1=="A42"]<-1
train$V4A42[train$V1!="A42"]<-0

train$V4A43[train$V1=="A43"]<-1
train$V4A43[train$V1!="A43"]<-0

train$V6A65[train$V1=="A65"]<-1
train$V6A65[train$V1!="A65"]<-0

train$V7A74[train$V1=="A74"]<-1
train$V7A74[train$V1!="A74"]<-0

train$V9A92[train$V1=="A92"]<-1
train$V9A92[train$V1!="A92"]<-0

train$V9A93[train$V1=="A93"]<-1
train$V9A93[train$V1!="A93"]<-0

train$V10A103[train$V1=="A103"]<-1
train$V10A103[train$V1!="A103"]<-0

train$V12A124[train$V1=="A124"]<-1
train$V12A124[train$V1!="A124"]<-0

train$V14A143[train$V1=="A143"]<-1
train$V14A143[train$V1!="A143"]<-0

train$V19A192[train$V1=="A192"]<-1
train$V19A192[train$V1!="A192"]<-0

train$V20A202[train$V1=="A202"]<-1
train$V20A202[train$V1!="A202"]<-0
```
#re-fit the model with these significant variables
```{r}
log3<-glm(V21~V1A12+V1A13+V1A14+V2+V3A34+V4A41+V4A42+V4A43+V5+V6A65+V7A74+V8+V9A92+V9A93+V10A103+V12A124+V14A143+V16+V19A192+V20A202,data=train,family=binomial(link="logit"))
summary(log3)
```
#only keep the significant terms
```{r}
log4<-glm(V21~V1A12+V1A13+V1A14+V2+V5+V8,data=train,family=binomial(link="logit"))
summary(log4)
```
#Now every term are significant, this is the final model

#Add the remained binary variables to the test dataset
```{r}
test$V1A12[test$V1=="A12"]<-1
test$V1A12[test$V1!="A12"]<-0

test$V1A13[test$V1=="A13"]<-1
test$V1A13[test$V1!="A13"]<-0

test$V1A14[test$V1=="A14"]<-1
test$V1A14[test$V1!="A14"]<-0
```

#validate the model using the test dataset
```{r}
yhatlog<-predict(log4,test,type = "response")
head(yhatlog)
```
#round the yhatlog to be 0/1 variabls
```{r}
y<- as.integer(yhatlog > 0.5)
head(y)

t <- table(y,test$V21)
t

correct<-(182+33)/300
correct

roc<-roc(test$V21,y)
```

# Plot the ROC curve
```{r}
plot(roc)
roc
```
#The model I developed is: log(p/(1-p))=-1.285e+00-5.099e-01*V1A12-1.155e+00*V1A13-2.316e+00*V1A14+2.545e-02*V2+9.637e-05*V5+1.633e-01*V8
The accuracy rate is 71.67%, AIC is 717.06,and AUC is 61.67%,which means the model will correctly classify the samples 61.67% of the times.

#2. Because the model gives a result between 0 and 1, it requires setting a threshold probability to
separate between ��good�� and ��bad�� answers. In this data set, they estimate that incorrectly
identifying a bad customer as good, is 5 times worse than incorrectly classifying a good customer
as bad. Determine a good threshold probability based on your model.

Calulating loss for tthe cost for thresholds ranging from 0.01 to 1. 

```{r}
cost <- c()
for(i in 1:100){
        y.hat<- as.integer(yhatlog > (i/100)) #0.01-100
        
        table<-as.matrix(table(y.hat,test$V21))
        
        if(nrow(table)>1) { cst1 <- table[2,1] } else { cst1 <- 0 }
        if(ncol(table)>1) { cst2 <- table[1,2] } else { cst2 <- 0 }
        cost <- c(cost, cst1+cst2*5)
}

plot(c(1:100)/100,cost,xlab = "Threshold",ylab = "Cost")

which.min(cost)
cost
```
#when threshold=0.08, we have minimum cost 187.